# üéØ CBU Coding Challenge 2025: AON Team Final Submission

## üöÄ Our Philosophy: All or Nothing

Welcome to the final submission repository for **Team AON (All or Nothing)**. Our approach to this challenge was rooted in a deep, manual analysis and a step-by-step data processing methodology. We believe that the true predictive power of a model is born not from algorithmic complexity, but from meticulous attention to data quality.

Every line of code, every new feature, and every modeling decision was made and implemented by our team without the use of AI-based assistants.

---

---

## üìà Our Methodology: A Step-by-Step, Expert-Driven Approach

We consciously moved away from fully automated pipelines in favor of a deliberate, step-by-step process. This granted us complete control over data quality at every stage.

### 1. **Data Consolidation & Deep Cleaning**
- **Objective:** To build a single, unified dataset from 6 heterogeneous sources (`.csv`, `.xlsx`, `.parquet`, `.xml`, `.jsonl`) and to defuse all data "landmines".
- **Process:**
  - **Merging:** All data sources were carefully merged into a single comprehensive table.
  - **"Dirty" Field Sanitization:** We manually standardized numerical columns by removing currency symbols and separators (e.g., in `annual_income`, `loan_amount`).
  - **Categorical Standardization:** Inconsistent values, such as `Full-time`, `Fulltime`, and `FT` in the `employment_type` field, were unified into clean, consistent categories.

### 2. **Expert-Led Feature Engineering & Selection**
- **Objective:** To create features with maximum business relevance and to eliminate noise.
- **Process:**
  - **Logarithmic Transformation:** We applied a log transform to key financial indicators to normalize their distributions.
  - **Interaction Feature Creation:** New features were generated by combining key variables (e.g., `credit_score` + `marital_status`).
  - **Outlier Capping:** Extreme values in several features were capped at the 85th percentile to reduce their skewing effect.
  - **Binning:** Continuous variables like `interest_rate` were discretized into bins to better capture non-linear relationships.
  - **Manual Target Encoding:** We engineered `problem_education` and `problem_maritial` features, which encode the mean default rate for each category, directly infusing target information into the model.

### 3. **Modeling: CatBoost + PCA**
- **Objective:** To build the final, most accurate predictive model.
- **Process:**
  - **Model Comparison:** During the cross-validation phase, we benchmarked `Logistic Regression`, `Random Forest`, and `CatBoost`. **CatBoost** delivered the best performance **(AUC 0.8297)** and was selected as our champion model.
  - **Dimensionality Reduction (PCA):** Before training the final model, we applied Principal Component Analysis (PCA) to reduce noise and dimensionality, transforming the feature set into 59 orthogonal, high-information components.
  - **Final Training:** The `CatBoost` model was trained on the PCA-transformed data.

---

## üìä Final Results

Our meticulous, step-by-step approach and the use of a powerful PCA + CatBoost combination enabled us to achieve the following results:

- **Cross-Validation AUC (Model Selection): 0.8297**
- **Final AUC on the Full Training Set: 0.8827**
- **F1-Score on the Full Training Set: 0.4010**

These metrics demonstrate the high predictive capability of our final model.

---

## üõ†Ô∏è Technology Stack

- **Core:** `Python`, `Pandas`, `NumPy`, `Scikit-learn`
- **Modeling:** `CatBoost`, `Logistic Regression`, `Random Forest`
- **Key Techniques:** `PCA (Principal Component Analysis)`, `One-Hot Encoding`

---

## ü§ù Team AON

We are Team AON. Our approach proves that a deep understanding of the data, combined with expert-driven manual processing, is the key to building world-class predictive models.

**All or Nothing.**